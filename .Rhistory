#'  and so on. This generates (I-1)(J-1) unique partioned tables for a given IxJ input.
#'  The Chi-squared and G-sqaured test for each partition is calculated.
#'  Comparision of overall Chi-sqaured and G-squared value is done with the sumation of the
#'  Chi-squared and G-sqaured values of the partioned tables
#' @param mat - matrix for which the sub-matrix is to be generated
#' @param details - If this is set to TRUE, the the return value includes the full list of
#' partioned tables with its Chi-sqaured and G-squared values
#' @details  A partitioning may show that an association reflects primarily differences between certain
#'  categories or groupings of categories.
#' @return A list of dataframes with
#'  \item{Chisq.compare}{  Dataframe with the difference between the supporting matrix and the opposing matrix}
#'  \item{Gsq.compare }{ Dataframe of the cell counts for support of table level Chi-sqaured }
#'  \item{Partitioning.df }{ Dataframe of partioned tables with its Chi-squared and G-squared values
#'  - this is returned only if the details flag is set to TRUE }
#' @family IxJ Inference methods
#' @examples
#' Example  - Agresti CDA 2002 p82 Section 3.3.3 - Example 3.3.4 is illustrated here.
#' mat=matrix(c(90,12,78,13,1,6,19,13,50),3,3,byrow = TRUE)
#' Partition.table(mat,details=FALSE)
#' @references
#' [1] Mosteller F, Parunak A (2006)
#' Identifying extreme cells in a sizable contingency table: Probabilistic and exploratory approaches.
#' In: Hoaglin DC, Mosteller F, Tukey JW (eds) Exploring Data Tables, Trends, and Shapes,
#' John Wiley & Sons, pp 189-224
#' @export
Partition.table<-function(mat,details=FALSE){
if (missing(mat)) stop("'mat' is missing")
if ((class(mat) != "matrix"))  stop("'mat' has to be a matrix with minimum 2x2")
if ((dim(mat)[1] < 2) || (dim(mat)[2] <2 )) stop("Matrix has to be minimum of 2x2")
if ((class(details) != "logical")) stop("details has to be a logical vector")
Partitioning.df = NULL
Total.columns=ncol(mat)
Total.rows=nrow(mat)
a=1:Total.rows
b=1:Total.columns
# Take cols first and then find the row elements for each col combination
# Column.combos=Total.columns-2
for(Row.iterator in 2:Total.rows){
for(Column.iterator in 2:Total.columns){
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
#  write.table(out.full,"D:/Research/CDA/Testing/Full.out.csv",append=TRUE,row.names=FALSE, col.names = FALSE, sep=",")
} #End of for-loop Column.iterator
} # End of for loop in Row.iterator for the current col combination
names(Partitioning.df)=c("a","b","c","d","Chisq","Gsq")
Chisq.compare = data.frame(Original.table.Chisq=chisq.test(mat)$statistic, Partition.table.Chisq.sum=colSums(Partitioning.df$ChiSq))
Gsq.compare = data.frame(Original.table.Gsq=GSquared(mat)$GSq, Partition.table.Gsq.sum=colSums(Partitioning.df$G.Squared))
if(details)
{Partitioning.list =list(Chisq.compare,Gsq.compare, Partitioning.df)
}else {Partitioning.list=list(Chisq.compare,Gsq.compare)}
return(Partitioning.list)
} # End of function
Partition.table(mat,details=FALSE)
Partitioning.df
Row.iterator
Column.iterator
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
Partitioning.df = NULL
Total.columns=ncol(mat)
Total.rows=nrow(mat)
a=1:Total.rows
b=1:Total.columns
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
Partitioning.df
Column.iterator=3
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
Row.iterator=3
Column.iterator=2
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
Column.iterator=3
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
Partitioning.df
names(Partitioning.df)=c("a","b","c","d","Chisq","Gsq")
Chisq.compare = data.frame(Original.table.Chisq=chisq.test(mat)$statistic, Partition.table.Chisq.sum=colSums(Partitioning.df$ChiSq))
colSums(Partitioning.df$Chisq)
(Partitioning.df$Chisq)
sum(Partitioning.df$Chisq)
class(Partitioning.df)
Chisq.compare = data.frame(Original.table.Chisq=chisq.test(mat)$statistic, Partition.table.Chisq.sum=sum(Partitioning.df$ChiSq))
Gsq.compare = data.frame(Original.table.Gsq=GSquared(mat)$GSq, Partition.table.Gsq.sum=sum(Partitioning.df$G.Squared))
Chisq.compare
sum(Partitioning.df$ChiSq)
(Partitioning.df$ChiSq)
Partitioning.df$Chisq
Chisq.compare = data.frame(Original.table.Chisq=chisq.test(mat)$statistic, Partition.table.Chisq.sum=sum(Partitioning.df$Chisq))
Gsq.compare = data.frame(Original.table.Gsq=GSquared(mat)$GSq, Partition.table.Gsq.sum=sum(Partitioning.df$Gsq))
Chisq.compare
Gsq.compare
#'  A partitioning may show that an association reflects primarily differences between certain
#'  categories or groupings of categories. In case of IxJ table, independent chi-squared components
#'  result from comparing columns 1 and 2 and then combining them and comparing them to column 3,
#'  and so on. This generates (I-1)(J-1) unique partioned tables for a given IxJ input.
#'  The Chi-squared and G-sqaured test for each partition is calculated.
#'  Comparision of overall Chi-sqaured and G-squared value is done with the sumation of the
#'  Chi-squared and G-sqaured values of the partioned tables
#' @param mat - matrix for which the sub-matrix is to be generated
#' @param details - If this is set to TRUE, the the return value includes the full list of
#' partioned tables with its Chi-sqaured and G-squared values
#' @details  A partitioning may show that an association reflects primarily differences between certain
#'  categories or groupings of categories.
#' @return A list of dataframes with
#'  \item{Chisq.compare}{  Dataframe with the difference between the supporting matrix and the opposing matrix}
#'  \item{Gsq.compare }{ Dataframe of the cell counts for support of table level Chi-sqaured }
#'  \item{Partitioning.df }{ Dataframe of partioned tables with its Chi-squared and G-squared values
#'  - this is returned only if the details flag is set to TRUE }
#' @family IxJ Inference methods
#' @examples
#' Example  - Agresti CDA 2002 p82 Section 3.3.3 - Example 3.3.4 is illustrated here.
#' mat=matrix(c(90,12,78,13,1,6,19,13,50),3,3,byrow = TRUE)
#' Partition.table(mat,details=FALSE)
#' @references
#' [1] Mosteller F, Parunak A (2006)
#' Identifying extreme cells in a sizable contingency table: Probabilistic and exploratory approaches.
#' In: Hoaglin DC, Mosteller F, Tukey JW (eds) Exploring Data Tables, Trends, and Shapes,
#' John Wiley & Sons, pp 189-224
#' @export
Partition.table<-function(mat,details=FALSE){
if (missing(mat)) stop("'mat' is missing")
if ((class(mat) != "matrix"))  stop("'mat' has to be a matrix with minimum 2x2")
if ((dim(mat)[1] < 2) || (dim(mat)[2] <2 )) stop("Matrix has to be minimum of 2x2")
if ((class(details) != "logical")) stop("details has to be a logical vector")
Partitioning.df = NULL
Total.columns=ncol(mat)
Total.rows=nrow(mat)
a=1:Total.rows
b=1:Total.columns
# Take cols first and then find the row elements for each col combination
# Column.combos=Total.columns-2
for(Row.iterator in 2:Total.rows){
for(Column.iterator in 2:Total.columns){
otemp=gmat(a,b,Row.iterator,Column.iterator,mat)
out.full = data.frame(a=otemp[1,1],b=otemp[1,2],c=otemp[2,1],d=otemp[2,2],
ChiSq=chisq.test(otemp)$statistic,
G.Squared=GSquared(otemp)$GSq)
Partitioning.df = rbind(Partitioning.df, out.full)
#  write.table(out.full,"D:/Research/CDA/Testing/Full.out.csv",append=TRUE,row.names=FALSE, col.names = FALSE, sep=",")
} #End of for-loop Column.iterator
} # End of for loop in Row.iterator for the current col combination
names(Partitioning.df)=c("a","b","c","d","Chisq","Gsq")
Chisq.compare = data.frame(Original.table.Chisq=chisq.test(mat)$statistic, Partition.table.Chisq.sum=sum(Partitioning.df$Chisq))
Gsq.compare = data.frame(Original.table.Gsq=GSquared(mat)$GSq, Partition.table.Gsq.sum=sum(Partitioning.df$Gsq))
if(details)
{Partitioning.list =list(Chisq.compare,Gsq.compare, Partitioning.df)
}else {Partitioning.list=list(Chisq.compare,Gsq.compare)}
return(Partitioning.list)
} # End of function
Partition.table(mat,details=FALSE)
Partition.table(mat,details=TRUE)
#'  This function  implements 9 methods for testing 2x2 tables and outputs the p-value
#'  In hypergemetric notation out of N = m+n items r size is chosen; x is observed success
#' @param x - Numeric value representing no of success in attribute 1.
#' @param m - Numeric value representing Total no of attribute 1
#' @param n - Numeric value representing Total no of attribute 2
#' @param r - Numeric value representing Total number of success
#' @details  Nine methods - IRWIN, Central, Blaker.exact, MP_IR, MP_BK, Exact.less,
#' Exact.greater, Pearson.Chisq, Pearson.Chisq.Yates.cc are implimented from
#' exact2x2 package (7 methods) and 2 methods from base stats
#' @return A dataframe with
#'  \item{IRWIN} {Fisher exact test with 'minlike'}
#'  \item{Central} {Fisher exact test with 'central'}
#'  \item{Blaker.exact} {Blaker exact test }
#'  \item{MP_IR} {Fisher exact test with 'minlike', hypergeometric}
#'  \item{MP_BK} {Blaker exact test, hypergeometric}
#'  \item{Exact.less} {Fisher exact test if one sided is less}
#'  \item{Exact.greater} {Fisher exact test if one sided is greater}
#'  \item{Pearson.Chisq} {Pearson Chisquared test}
#'  \item{Pearson.Chisq.Yates.cc} {Pearson Chisquared test with Yates continuity correction}
#' @family Test methods
#' @seealso
#'    \code{\link[exact2x2]{fisher.exact} {blaker.exact}} with additional parameters. This function calls exact2x2 functions.
#'    \code{\link[stats]{chisq.test}} with additional parameters. This function calls base stats function.
#' @examples
#' Example taken from -p28 Ex3.1 of Upton, G. J. (2016).
#' Values are x,m,n,r: related to a hypergeometric distribution (?dhyper, for further help)
#' x=1; m=3; n=10; r=4
#' exact2x2tests.hypergeom(x,m,n,r)
#' @references
#' [1] Upton, G. J. (2016).
#' Categorical Data Analysis by Example.
#' John Wiley & Sons.
#' @export
exact2x2tests.hypergeom<-function(x,m,n,r)
{
if ((class(x) != "numeric") & (class(x) != "integer") ||
(class(m) != "numeric")  & (class(m) != "integer")   ||
(class(n) != "numeric")  & (class(n) != "integer")  ||
(class(r) != "numeric")  & (class(r) != "integer"))   stop("Inputs x,m,n and r have to be numeric")
if (m < 0 || n<0) stop("m and n have to be  greater or equal to zero")
if (x > m || x<0) stop("x has to be  greater or equal to zero and less than or equal to m")
if (r >= n+x || r<0) stop("r has to be  greater or equal to zero and less than or equal to n+x")
dat=matrix(c(x,m-x,r-x,n-r+x),2,2,byrow=TRUE)
IRWIN=fisher.exact(dat,tsmethod="minlike")$p.value
CDT=fisher.exact(dat,tsmethod="central")$p.value
BKR=blaker.exact(dat)$p.value
MP_IR=fisher.exact(dat,tsmethod="minlike")$p.value-0.5*dhyper(x, m, n, r, log = FALSE)
MP_BK=blaker.exact(dat)$p.value-0.5*dhyper(x, m, n, r, log = FALSE)
EXA_L=fisher.exact(dat,alternative = "less")$p.value
EXA_G=fisher.exact(dat,alternative = "greater")$p.value
PEAR=chisq.test(dat)$p.value
PEAR_YCC=chisq.test(dat,correct = TRUE)$p.value
ans.tests.df=data.frame(IRWIN=round(IRWIN,4),
Central=round(CDT,4),
Blaker.exact=round(BKR,4),
MP_IR= round(MP_IR,4),
MP_BK= round(MP_BK,4),
Exact.less=round(EXA_L,4),
Exact.greater=round(EXA_G,4),
Pearson.Chisq=round(PEAR,4),
Pearson.Chisq.Yates.cc=round(PEAR_YCC,4))
return(ans.tests.df)
}
####################################################################################################
#'  This function  implements 9 methods for testing 2x2 tables and outputs the p-value
#'  This is the regular function taking the 2x2 table as input
#' @param ai - Numeric value representing True Positives
#' @param bi - Numeric value representing False Positives
#' @param ci - Numeric value representing False Negatives
#' @param di - Numeric value representing True Negatives
#' @details  Nine methods - IRWIN, Central, Blaker.exact, MP_IR, MP_BK, Exact.less,
#' Exact.greater, Pearson.Chisq, Pearson.Chisq.Yates.cc are implimented from
#' exact2x2 package (7 methods) and 2 methods from base stats
#' @return A dataframe with
#'  \item{IRWIN} {Fisher exact test with 'minlike'}
#'  \item{Central} {Fisher exact test with 'central'}
#'  \item{Blaker.exact} {Blaker exact test }
#'  \item{MP_IR} {Fisher exact test with 'minlike', hypergeometric}
#'  \item{MP_BK} {Blaker exact test, hypergeometric}
#'  \item{Exact.less} {Fisher exact test if one sided is less}
#'  \item{Exact.greater} {Fisher exact test if one sided is greater}
#'  \item{Pearson.Chisq} {Pearson Chisquared test}
#'  \item{Pearson.Chisq.Yates.cc} {Pearson Chisquared test with Yates continuity correction}
#' @family Test methods
#' @seealso
#'    \code{\link[exact2x2]{fisher.exact} {blaker.exact}} with additional parameters. This function calls exact2x2 functions.
#'    \code{\link[stats]{chisq.test}} with additional parameters. This function calls base stats function.
#' @examples
#' Example taken from -p28 Ex3.1 of Upton, G. J. (2016).
#' ai=1; bi=3; ci=10; di=4
#' exact2x2tests.regular(ai,bi,ci,di)
#' @references
#' [1] Upton, G. J. (2016).
#' Categorical Data Analysis by Example.
#' John Wiley & Sons.
#' @export
exact2x2tests.regular<-function(ai,bi,ci,di)
{
if ((class(ai) != "numeric") & (class(ai) != "integer") ||
(class(bi) != "numeric")  & (class(bi) != "integer")   ||
(class(ci) != "numeric")  & (class(ci) != "integer")  ||
(class(di) != "numeric")  & (class(di) != "integer"))   stop("Inputs ai,bi,ci and di have to be numeric")
x=c(ai,bi,ci,di)
dat=matrix(x,2,2)
IRWIN=fisher.exact(dat,tsmethod="minlike")$p.value
CDT=fisher.exact(dat,tsmethod="central")$p.value
BKR=blaker.exact(dat)$p.value
MP_IR=fisher.exact(dat,tsmethod="minlike")$p.value-0.5*dhyper(x, m, n, r, log = FALSE)
MP_BK=blaker.exact(dat)$p.value-0.5*dhyper(x, m, n, r, log = FALSE)
EXA_L=fisher.exact(dat,alternative = "less")$p.value
EXA_G=fisher.exact(dat,alternative = "greater")$p.value
PEAR=chisq.test(dat)$p.value
PEAR_YCC=chisq.test(dat,correct = TRUE)$p.value
ans.tests.df=data.frame(IRWIN=round(IRWIN,4),
Central=round(CDT,4),
Blaker.exact=round(BKR,4),
MP_IR= round(MP_IR,4),
MP_BK= round(MP_BK,4),
Exact.less=round(EXA_L,4),
Exact.greater=round(EXA_G,4),
Pearson.Chisq=round(PEAR,4),
Pearson.Chisq.Yates.cc=round(PEAR_YCC,4))
return(ans.tests.df)
}
x=1; m=3; n=10; r=4
exact2x2tests.hypergeom(x,m,n,r)
exact2x2tests.regular(ai,bi,ci,di)
mat=matrix(c(90,12,78,13,1,6,19,13,50),3,3,byrow = TRUE)
Partition.table(mat,details=FALSE)
Partition.table(mat,details=TRUE)
version
library(vcdPlus)
library(vcdPlus)
?ci.WS
??ci.WS
SumZeroData(2,3,2,1)
ai=7; bi=11; ci=1; di=17; alp=0.05; e1=0.5; e2=0.5
Association.Measures.OR(ai, bi, ci, di, alp, e1, e2)
?Woolf.CI
?Prop.diff
?gather
??gather
detach(vcdplus)
detach(vcdPlus)
detach("vcdPlus")
library("vcdPlus", lib.loc="C:/Program Files/R/R-3.3.3/library")
detach("package:vcdPlus", unload=TRUE)
devtools::install()
devtools::install()
devtools::install()
?mutate
?blaker.exact
?tbl_df
??tbl_df
??%>%
?rownames_to_column
?rownames_to_column
## Example taken from Fagerland and Newcombe [reference 1]
devtools::document()
#'  \item{Significance at 95%}{Test for significance at 95%}
devtools::document()
library(vcdPlus)
Drills=c(2,	10,	4,	2 )
Pots= c(3,	8,	4,	6)
Grinding.Stones=c( 13, 5, 3, 9)
Point.Fragments=c(20, 36, 19, 20)
mat=rbind(Drills,Pots,Grinding.Stones,Point.Fragments)
generate.heatmap(mat)
devtools::document()
library(vcdPlus)
devtools::document()
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
a=c(90,	12,	78) # Example from [reference 4]
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
library(vcdPlus)
devtools::run_examples()
devtools::run_examples()
devtools::run_examples()
devtools::run_examples()
devtools::run_examples()
devtools::run_examples()
PRO_DITE=function(x)
{
a=x[1]
b=x[2]
c=x[3]
d=x[4]
p=x[5]
m = a + b
n = c + d
r = a + c
s =  b + d
SENST=a/r
SPECI=d/s
JINDX=SENST+SPECI-1
PPV=a/m
NPV=d/n
PLR=SENST/(1-SPECI)
NLR=(1-SENST)/SPECI
PPV_p = SENST*p/(SENST*p+(1-SPECI)*(1-p))
NPV_p = SPECI*(1-p)/((1-SENST)*p+SPECI*(1-p))
ans=round(rbind(SENST,SPECI,JINDX,PPV,NPV,PLR,NLR,PPV_p,NPV_p),4)
colnames(ans)=c("Estimates")
ans
}
####EXAMPLE-from Mercaldo (2007)
x=c(31,12,3,32,0.07)
RES=PRO_DITE(x)
######Interval estimation
alp=0.05
r=5000
p=0.07
x_B=matrix(0,r,4)
RES_B=matrix(0,9,r)
for(i in 1:r)
{
x_B[i,] = rmultinom(1,sum(x[-5]),prob = x[-5]/sum(x[-5]))
RES_B[,i] = PRO_DITE(c(x_B[i,],p))
}
LL=0
UL=0
for(j in 1:9)
{
LL[j]=round(quantile(RES_B[j,],alp/2),4)
UL[j]=round(quantile(RES_B[j,],1-(alp/2)),4)
}
cbind(RES,LL,UL,WidthCI=UL-LL)
i
i=1
x_B[i,] = rmultinom(1,sum(x[-5]),prob = x[-5]/sum(x[-5]))
x_B[i,]
x_B[i,][1]
x_B[i,][2]
x_B[i,][3]
x_B[i,][4]
devtools::run_examples()
x_B
x_B[1,]
x_B[1,][1]
x_B[100,][1]
ai=31; bi=12; ci=3; di=32; p=0.07
RES=Proportion.diagnostic.test(ai,bi,ci,di,p)
x=c(ai,bi,ci,di,p)
alp=0.05
r=5000
p=0.07
x_B=matrix(0,r,4)
RES_B=matrix(0,9,r)
for(i in 1:r)
{
x_B[i,] = rmultinom(1,sum(x[-5]),prob = x[-5]/sum(x[-5]))
RES_B[,i] = Proportion.diagnostic.test(x_B[i,][1],x_B[i,][2],x_B[i,][3],x_B[i,][4],p)
}
i=1
x_B[i,] = rmultinom(1,sum(x[-5]),prob = x[-5]/sum(x[-5]))
RES_B[,i] = Proportion.diagnostic.test(x_B[i,][1],x_B[i,][2],x_B[i,][3],x_B[i,][4],p)
x_B[i,][1]
ai=31; bi=12; ci=3; di=32; p=0.07
RES=Proportion.diagnostic.test(ai,bi,ci,di,p)
x=c(ai,bi,ci,di)
alp=0.05
r=5000
p=0.07
x_B=matrix(0,r,4)
RES_B=matrix(0,9,r)
for(i in 1:r)
{
x_B[i,] = rmultinom(1,sum(x[-5]),prob = x[-5]/sum(x[-5]))
ai=x_B[i,][1]
bi=x_B[i,][1]
ci=x_B[i,][1]
di=x_B[i,][1]
RES_B[,i] = Proportion.diagnostic.test(ai,bi,ci,di,p)
}
LL=0
UL=0
for(j in 1:9)
{
LL[j]=round(quantile(RES_B[j,],alp/2),4)
UL[j]=round(quantile(RES_B[j,],1-(alp/2)),4)
}
cbind(RES,LL,UL,WidthCI=UL-LL)
devtools::run_examples()
devtools::run_examples()
Drills=c(2,	10,	4,	2 ) # Example data from [reference 1]
Pots= c(3,	8,	4,	6)
Grinding.Stones=c( 13, 5, 3, 9)
Point.Fragments=c(20, 36, 19, 20)
mat=rbind(Drills,Pots,Grinding.Stones,Point.Fragments)
generate.heatmap.matrix(mat,details=FALSE)
generate.heatmap(mat)
Eclectic=c(90,	12,	78) # Example from [reference 4]
Medical=c(13,	1,	6)
Psychoanalytic=c(19,	13,	50)
mat=rbind(Eclectic,Medical,Psychoanalytic)
Reversal.Association.Finder(mat)
ai=80; bi=1; ci=39; di=0
Reversal.point(ai,bi,ci,di)
x = c(56,72,73,59,62,87,68,99,98)
inpmat = cbind(x[1:3],x[4:6],x[7:9])
alpha=0.05
ci.QH(inpmat,alpha)
ci.GM(inpmat,alpha)
x=c(7,61,55,129,489,570,475,431,293,154,38,12)
inpmat = cbind(x[1:4],x[5:8],x[9:12])
SumZeroData(inpmat)
mat=matrix(c(1:9), nrow=3, ncol=3)
Nominal.Odds.Ratio(mat,Reference.Row.ID=3, Reference.Col.ID=3 ) # Same as Nominal.Odds.Ratio(mat)
Nominal.Odds.Ratio(mat, 2, 2)
Local.Odds.Ratio(mat)
Subtable.Odds.Ratio(mat)
ai=31; bi=12; ci=3; di=32; p=0.07
Proportion.diagnostic.test(ai,bi,ci,di,p)
?fisher.exact
library(vcdPlus)
devtools::install_github("rajeswaranv/vcdPlus")
version
